{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import os \n",
    "import numpy as np\n",
    "import xml.etree.ElementTree as ET\n",
    "from collections import OrderedDict\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_single_xml_file(tree):\n",
    "    Nobj = 0\n",
    "    row  = OrderedDict()\n",
    "    for elems in tree.iter():\n",
    "\n",
    "        if elems.tag == \"size\":\n",
    "            for elem in elems:\n",
    "                row[elem.tag] = int(elem.text)\n",
    "        if elems.tag == \"object\":\n",
    "            for elem in elems:\n",
    "                if elem.tag == \"name\":\n",
    "                    row[\"bbx_{}_{}\".format(Nobj,elem.tag)] = str(elem.text)              \n",
    "                if elem.tag == \"bndbox\":\n",
    "                    for k in elem:\n",
    "                        row[\"bbx_{}_{}\".format(Nobj,k.tag)] = float(k.text)\n",
    "                    Nobj += 1\n",
    "    row[\"Nobj\"] = Nobj\n",
    "    return(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_anno = \"DLAssignment/annot/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "columns in df_anno\n",
      "-----------------\n",
      "  0: width\n",
      "  1: height\n",
      "  2: depth\n",
      "  3: bbx_0_name\n",
      "  4: bbx_0_xmin\n",
      "  5: bbx_0_ymin\n",
      "  6: bbx_0_xmax\n",
      "  7: bbx_0_ymax\n",
      "  8: bbx_1_name\n",
      "  9: bbx_1_xmin\n",
      " 10: bbx_1_ymin\n",
      " 11: bbx_1_xmax\n",
      " 12: bbx_1_ymax\n",
      " 13: bbx_2_name\n",
      " 14: bbx_2_xmin\n",
      " 15: bbx_2_ymin\n",
      " 16: bbx_2_xmax\n",
      " 17: bbx_2_ymax\n",
      " 18: bbx_3_name\n",
      " 19: bbx_3_xmin\n",
      " 20: bbx_3_ymin\n",
      " 21: bbx_3_xmax\n",
      " 22: bbx_3_ymax\n",
      " 23: bbx_4_name\n",
      " 24: bbx_4_xmin\n",
      " 25: bbx_4_ymin\n",
      " 26: bbx_4_xmax\n",
      " 27: bbx_4_ymax\n",
      " 28: bbx_5_name\n",
      " 29: bbx_5_xmin\n",
      " 30: bbx_5_ymin\n",
      " 31: bbx_5_xmax\n",
      " 32: bbx_5_ymax\n",
      " 33: bbx_6_name\n",
      " 34: bbx_6_xmin\n",
      " 35: bbx_6_ymin\n",
      " 36: bbx_6_xmax\n",
      " 37: bbx_6_ymax\n",
      " 38: bbx_7_name\n",
      " 39: bbx_7_xmin\n",
      " 40: bbx_7_ymin\n",
      " 41: bbx_7_xmax\n",
      " 42: bbx_7_ymax\n",
      " 43: bbx_8_name\n",
      " 44: bbx_8_xmin\n",
      " 45: bbx_8_ymin\n",
      " 46: bbx_8_xmax\n",
      " 47: bbx_8_ymax\n",
      " 48: bbx_9_name\n",
      " 49: bbx_9_xmin\n",
      " 50: bbx_9_ymin\n",
      " 51: bbx_9_xmax\n",
      " 52: bbx_9_ymax\n",
      " 53: bbx_10_name\n",
      " 54: bbx_10_xmin\n",
      " 55: bbx_10_ymin\n",
      " 56: bbx_10_xmax\n",
      " 57: bbx_10_ymax\n",
      " 58: bbx_11_name\n",
      " 59: bbx_11_xmin\n",
      " 60: bbx_11_ymin\n",
      " 61: bbx_11_xmax\n",
      " 62: bbx_11_ymax\n",
      " 63: bbx_12_name\n",
      " 64: bbx_12_xmin\n",
      " 65: bbx_12_ymin\n",
      " 66: bbx_12_xmax\n",
      " 67: bbx_12_ymax\n",
      " 68: bbx_13_name\n",
      " 69: bbx_13_xmin\n",
      " 70: bbx_13_ymin\n",
      " 71: bbx_13_xmax\n",
      " 72: bbx_13_ymax\n",
      " 73: bbx_14_name\n",
      " 74: bbx_14_xmin\n",
      " 75: bbx_14_ymin\n",
      " 76: bbx_14_xmax\n",
      " 77: bbx_14_ymax\n",
      " 78: bbx_15_name\n",
      " 79: bbx_15_xmin\n",
      " 80: bbx_15_ymin\n",
      " 81: bbx_15_xmax\n",
      " 82: bbx_15_ymax\n",
      " 83: bbx_16_name\n",
      " 84: bbx_16_xmin\n",
      " 85: bbx_16_ymin\n",
      " 86: bbx_16_xmax\n",
      " 87: bbx_16_ymax\n",
      " 88: bbx_17_name\n",
      " 89: bbx_17_xmin\n",
      " 90: bbx_17_ymin\n",
      " 91: bbx_17_xmax\n",
      " 92: bbx_17_ymax\n",
      " 93: bbx_18_name\n",
      " 94: bbx_18_xmin\n",
      " 95: bbx_18_ymin\n",
      " 96: bbx_18_xmax\n",
      " 97: bbx_18_ymax\n",
      " 98: bbx_19_name\n",
      " 99: bbx_19_xmin\n",
      "100: bbx_19_ymin\n",
      "101: bbx_19_xmax\n",
      "102: bbx_19_ymax\n",
      "103: bbx_20_name\n",
      "104: bbx_20_xmin\n",
      "105: bbx_20_ymin\n",
      "106: bbx_20_xmax\n",
      "107: bbx_20_ymax\n",
      "108: bbx_21_name\n",
      "109: bbx_21_xmin\n",
      "110: bbx_21_ymin\n",
      "111: bbx_21_xmax\n",
      "112: bbx_21_ymax\n",
      "113: bbx_22_name\n",
      "114: bbx_22_xmin\n",
      "115: bbx_22_ymin\n",
      "116: bbx_22_xmax\n",
      "117: bbx_22_ymax\n",
      "118: bbx_23_name\n",
      "119: bbx_23_xmin\n",
      "120: bbx_23_ymin\n",
      "121: bbx_23_xmax\n",
      "122: bbx_23_ymax\n",
      "123: bbx_24_name\n",
      "124: bbx_24_xmin\n",
      "125: bbx_24_ymin\n",
      "126: bbx_24_xmax\n",
      "127: bbx_24_ymax\n",
      "128: bbx_25_name\n",
      "129: bbx_25_xmin\n",
      "130: bbx_25_ymin\n",
      "131: bbx_25_xmax\n",
      "132: bbx_25_ymax\n",
      "133: bbx_26_name\n",
      "134: bbx_26_xmin\n",
      "135: bbx_26_ymin\n",
      "136: bbx_26_xmax\n",
      "137: bbx_26_ymax\n",
      "138: bbx_27_name\n",
      "139: bbx_27_xmin\n",
      "140: bbx_27_ymin\n",
      "141: bbx_27_xmax\n",
      "142: bbx_27_ymax\n",
      "143: bbx_28_name\n",
      "144: bbx_28_xmin\n",
      "145: bbx_28_ymin\n",
      "146: bbx_28_xmax\n",
      "147: bbx_28_ymax\n",
      "148: bbx_29_name\n",
      "149: bbx_29_xmin\n",
      "150: bbx_29_ymin\n",
      "151: bbx_29_xmax\n",
      "152: bbx_29_ymax\n",
      "153: bbx_30_name\n",
      "154: bbx_30_xmin\n",
      "155: bbx_30_ymin\n",
      "156: bbx_30_xmax\n",
      "157: bbx_30_ymax\n",
      "158: bbx_31_name\n",
      "159: bbx_31_xmin\n",
      "160: bbx_31_ymin\n",
      "161: bbx_31_xmax\n",
      "162: bbx_31_ymax\n",
      "163: bbx_32_name\n",
      "164: bbx_32_xmin\n",
      "165: bbx_32_ymin\n",
      "166: bbx_32_xmax\n",
      "167: bbx_32_ymax\n",
      "168: bbx_33_name\n",
      "169: bbx_33_xmin\n",
      "170: bbx_33_ymin\n",
      "171: bbx_33_xmax\n",
      "172: bbx_33_ymax\n",
      "173: bbx_34_name\n",
      "174: bbx_34_xmin\n",
      "175: bbx_34_ymin\n",
      "176: bbx_34_xmax\n",
      "177: bbx_34_ymax\n",
      "178: bbx_35_name\n",
      "179: bbx_35_xmin\n",
      "180: bbx_35_ymin\n",
      "181: bbx_35_xmax\n",
      "182: bbx_35_ymax\n",
      "183: bbx_36_name\n",
      "184: bbx_36_xmin\n",
      "185: bbx_36_ymin\n",
      "186: bbx_36_xmax\n",
      "187: bbx_36_ymax\n",
      "188: bbx_37_name\n",
      "189: bbx_37_xmin\n",
      "190: bbx_37_ymin\n",
      "191: bbx_37_xmax\n",
      "192: bbx_37_ymax\n",
      "193: bbx_38_name\n",
      "194: bbx_38_xmin\n",
      "195: bbx_38_ymin\n",
      "196: bbx_38_xmax\n",
      "197: bbx_38_ymax\n",
      "198: bbx_39_name\n",
      "199: bbx_39_xmin\n",
      "200: bbx_39_ymin\n",
      "201: bbx_39_xmax\n",
      "202: bbx_39_ymax\n",
      "203: bbx_40_name\n",
      "204: bbx_40_xmin\n",
      "205: bbx_40_ymin\n",
      "206: bbx_40_xmax\n",
      "207: bbx_40_ymax\n",
      "208: bbx_41_name\n",
      "209: bbx_41_xmin\n",
      "210: bbx_41_ymin\n",
      "211: bbx_41_xmax\n",
      "212: bbx_41_ymax\n",
      "213: bbx_42_name\n",
      "214: bbx_42_xmin\n",
      "215: bbx_42_ymin\n",
      "216: bbx_42_xmax\n",
      "217: bbx_42_ymax\n",
      "218: bbx_43_name\n",
      "219: bbx_43_xmin\n",
      "220: bbx_43_ymin\n",
      "221: bbx_43_xmax\n",
      "222: bbx_43_ymax\n",
      "223: bbx_44_name\n",
      "224: bbx_44_xmin\n",
      "225: bbx_44_ymin\n",
      "226: bbx_44_xmax\n",
      "227: bbx_44_ymax\n",
      "228: bbx_45_name\n",
      "229: bbx_45_xmin\n",
      "230: bbx_45_ymin\n",
      "231: bbx_45_xmax\n",
      "232: bbx_45_ymax\n",
      "233: bbx_46_name\n",
      "234: bbx_46_xmin\n",
      "235: bbx_46_ymin\n",
      "236: bbx_46_xmax\n",
      "237: bbx_46_ymax\n",
      "238: bbx_47_name\n",
      "239: bbx_47_xmin\n",
      "240: bbx_47_ymin\n",
      "241: bbx_47_xmax\n",
      "242: bbx_47_ymax\n",
      "243: bbx_48_name\n",
      "244: bbx_48_xmin\n",
      "245: bbx_48_ymin\n",
      "246: bbx_48_xmax\n",
      "247: bbx_48_ymax\n",
      "248: bbx_49_name\n",
      "249: bbx_49_xmin\n",
      "250: bbx_49_ymin\n",
      "251: bbx_49_xmax\n",
      "252: bbx_49_ymax\n",
      "253: bbx_50_name\n",
      "254: bbx_50_xmin\n",
      "255: bbx_50_ymin\n",
      "256: bbx_50_xmax\n",
      "257: bbx_50_ymax\n",
      "258: bbx_51_name\n",
      "259: bbx_51_xmin\n",
      "260: bbx_51_ymin\n",
      "261: bbx_51_xmax\n",
      "262: bbx_51_ymax\n",
      "263: bbx_52_name\n",
      "264: bbx_52_xmin\n",
      "265: bbx_52_ymin\n",
      "266: bbx_52_xmax\n",
      "267: bbx_52_ymax\n",
      "268: bbx_53_name\n",
      "269: bbx_53_xmin\n",
      "270: bbx_53_ymin\n",
      "271: bbx_53_xmax\n",
      "272: bbx_53_ymax\n",
      "273: bbx_54_name\n",
      "274: bbx_54_xmin\n",
      "275: bbx_54_ymin\n",
      "276: bbx_54_xmax\n",
      "277: bbx_54_ymax\n",
      "278: bbx_55_name\n",
      "279: bbx_55_xmin\n",
      "280: bbx_55_ymin\n",
      "281: bbx_55_xmax\n",
      "282: bbx_55_ymax\n",
      "283: bbx_56_name\n",
      "284: bbx_56_xmin\n",
      "285: bbx_56_ymin\n",
      "286: bbx_56_xmax\n",
      "287: bbx_56_ymax\n",
      "288: bbx_57_name\n",
      "289: bbx_57_xmin\n",
      "290: bbx_57_ymin\n",
      "291: bbx_57_xmax\n",
      "292: bbx_57_ymax\n",
      "293: bbx_58_name\n",
      "294: bbx_58_xmin\n",
      "295: bbx_58_ymin\n",
      "296: bbx_58_xmax\n",
      "297: bbx_58_ymax\n",
      "298: Nobj\n",
      "299: fileID\n",
      "300: bbx_59_name\n",
      "301: bbx_59_xmin\n",
      "302: bbx_59_ymin\n",
      "303: bbx_59_xmax\n",
      "304: bbx_59_ymax\n",
      "------------------------------\n",
      "df_anno.shape=(127, 305)=(N frames, N columns)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>width</th>\n",
       "      <th>height</th>\n",
       "      <th>depth</th>\n",
       "      <th>bbx_0_name</th>\n",
       "      <th>bbx_0_xmin</th>\n",
       "      <th>bbx_0_ymin</th>\n",
       "      <th>bbx_0_xmax</th>\n",
       "      <th>bbx_0_ymax</th>\n",
       "      <th>bbx_1_name</th>\n",
       "      <th>bbx_1_xmin</th>\n",
       "      <th>...</th>\n",
       "      <th>bbx_58_ymin</th>\n",
       "      <th>bbx_58_xmax</th>\n",
       "      <th>bbx_58_ymax</th>\n",
       "      <th>Nobj</th>\n",
       "      <th>fileID</th>\n",
       "      <th>bbx_59_name</th>\n",
       "      <th>bbx_59_xmin</th>\n",
       "      <th>bbx_59_ymin</th>\n",
       "      <th>bbx_59_xmax</th>\n",
       "      <th>bbx_59_ymax</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3840</td>\n",
       "      <td>2748</td>\n",
       "      <td>3</td>\n",
       "      <td>1_a</td>\n",
       "      <td>771.0</td>\n",
       "      <td>377.0</td>\n",
       "      <td>1366.0</td>\n",
       "      <td>569.0</td>\n",
       "      <td>2_a</td>\n",
       "      <td>1387.0</td>\n",
       "      <td>...</td>\n",
       "      <td>604.0</td>\n",
       "      <td>1554.0</td>\n",
       "      <td>698.0</td>\n",
       "      <td>59</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3840</td>\n",
       "      <td>2748</td>\n",
       "      <td>3</td>\n",
       "      <td>1_a</td>\n",
       "      <td>769.0</td>\n",
       "      <td>366.0</td>\n",
       "      <td>1366.0</td>\n",
       "      <td>569.0</td>\n",
       "      <td>2_a</td>\n",
       "      <td>1387.0</td>\n",
       "      <td>...</td>\n",
       "      <td>613.0</td>\n",
       "      <td>1781.0</td>\n",
       "      <td>695.0</td>\n",
       "      <td>60</td>\n",
       "      <td>1</td>\n",
       "      <td>60_o</td>\n",
       "      <td>1443.0</td>\n",
       "      <td>613.0</td>\n",
       "      <td>1547.0</td>\n",
       "      <td>698.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3840</td>\n",
       "      <td>2748</td>\n",
       "      <td>3</td>\n",
       "      <td>1_a</td>\n",
       "      <td>769.0</td>\n",
       "      <td>366.0</td>\n",
       "      <td>1366.0</td>\n",
       "      <td>569.0</td>\n",
       "      <td>2_a</td>\n",
       "      <td>1387.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>58</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3840</td>\n",
       "      <td>2748</td>\n",
       "      <td>3</td>\n",
       "      <td>1_a</td>\n",
       "      <td>775.0</td>\n",
       "      <td>380.0</td>\n",
       "      <td>1358.0</td>\n",
       "      <td>541.0</td>\n",
       "      <td>2_a</td>\n",
       "      <td>1396.0</td>\n",
       "      <td>...</td>\n",
       "      <td>604.0</td>\n",
       "      <td>1775.0</td>\n",
       "      <td>694.0</td>\n",
       "      <td>60</td>\n",
       "      <td>10</td>\n",
       "      <td>60_o</td>\n",
       "      <td>1439.0</td>\n",
       "      <td>606.0</td>\n",
       "      <td>1540.0</td>\n",
       "      <td>700.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3840</td>\n",
       "      <td>2748</td>\n",
       "      <td>3</td>\n",
       "      <td>1_a</td>\n",
       "      <td>769.0</td>\n",
       "      <td>366.0</td>\n",
       "      <td>1366.0</td>\n",
       "      <td>569.0</td>\n",
       "      <td>2_a</td>\n",
       "      <td>1387.0</td>\n",
       "      <td>...</td>\n",
       "      <td>604.0</td>\n",
       "      <td>1563.0</td>\n",
       "      <td>710.0</td>\n",
       "      <td>59</td>\n",
       "      <td>11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 305 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   width  height  depth bbx_0_name  bbx_0_xmin  bbx_0_ymin  bbx_0_xmax  \\\n",
       "0   3840    2748      3        1_a       771.0       377.0      1366.0   \n",
       "1   3840    2748      3        1_a       769.0       366.0      1366.0   \n",
       "2   3840    2748      3        1_a       769.0       366.0      1366.0   \n",
       "3   3840    2748      3        1_a       775.0       380.0      1358.0   \n",
       "4   3840    2748      3        1_a       769.0       366.0      1366.0   \n",
       "\n",
       "   bbx_0_ymax bbx_1_name  bbx_1_xmin  ...  bbx_58_ymin  bbx_58_xmax  \\\n",
       "0       569.0        2_a      1387.0  ...        604.0       1554.0   \n",
       "1       569.0        2_a      1387.0  ...        613.0       1781.0   \n",
       "2       569.0        2_a      1387.0  ...          NaN          NaN   \n",
       "3       541.0        2_a      1396.0  ...        604.0       1775.0   \n",
       "4       569.0        2_a      1387.0  ...        604.0       1563.0   \n",
       "\n",
       "   bbx_58_ymax Nobj  fileID  bbx_59_name  bbx_59_xmin  bbx_59_ymin  \\\n",
       "0        698.0   59       1          NaN          NaN          NaN   \n",
       "1        695.0   60       1         60_o       1443.0        613.0   \n",
       "2          NaN   58      10          NaN          NaN          NaN   \n",
       "3        694.0   60      10         60_o       1439.0        606.0   \n",
       "4        710.0   59      11          NaN          NaN          NaN   \n",
       "\n",
       "  bbx_59_xmax  bbx_59_ymax  \n",
       "0         NaN          NaN  \n",
       "1      1547.0        698.0  \n",
       "2         NaN          NaN  \n",
       "3      1540.0        700.0  \n",
       "4         NaN          NaN  \n",
       "\n",
       "[5 rows x 305 columns]"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_anno = []\n",
    "for fnm in os.listdir(dir_anno):  \n",
    "    if not fnm.startswith('.'): ## do not include hidden folders/files\n",
    "        tree = ET.parse(os.path.join(dir_anno,fnm))\n",
    "        row = extract_single_xml_file(tree)\n",
    "        row[\"fileID\"] = fnm.split(\".\")[0]\n",
    "        df_anno.append(row)\n",
    "df_anno = pd.DataFrame(df_anno)\n",
    "\n",
    "maxNobj = np.max(df_anno[\"Nobj\"])\n",
    "\n",
    "\n",
    "print(\"columns in df_anno\\n-----------------\")\n",
    "for icol, colnm in enumerate(df_anno.columns):\n",
    "    print(\"{:3.0f}: {}\".format(icol,colnm))\n",
    "print(\"-\"*30)\n",
    "print(\"df_anno.shape={}=(N frames, N columns)\".format(df_anno.shape))\n",
    "df_anno.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(127, 305)"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_anno.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(101, 305)"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_anno[df_anno.Nobj == 60].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_anno[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df_anno[\"Nobj\"]\n",
    "X = df_anno.copy()\n",
    "x_t, x_v, y_t, y_v = train_test_split(X, y,stratify=y, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_file_idx = x_t.fileID\n",
    "val_file_idx = x_v.fileID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_img = [str(i) + \".jpg\" for i in train_file_idx]\n",
    "train_xml = [str(i) + \".xml\" for i in train_file_idx]\n",
    "val_img = [str(i) + \".jpg\" for i in val_file_idx]\n",
    "val_xml = [str(i) + \".xml\" for i in val_file_idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use above lists to make training and validation set as required by imageai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/hardikmalhotra/Desktop/ML/nanonets-interview'"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "annot_dir = Path(os.getcwd())/\"imageai_data\"/\"validation\"/\"annotations\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/Users/hardikmalhotra/Desktop/ML/nanonets-interview/imageai_data/validation/annotations')"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "annot_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "annot_dir = Path(os.getcwd())/\"imageai_data\"/\"validation\"/\"annotations\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "for f in os.listdir(annot_dir):\n",
    "    if \".xml\" in f:\n",
    "        d = ET.parse(annot_dir/f)\n",
    "        f_name = f.split(\".\")[0]\n",
    "        d.find(\"filename\").text = f_name + \".jpg\"\n",
    "        d.find(\"folder\").text = \"images\"\n",
    "        d.write(annot_dir/f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'86.xml'"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'86.jpg'"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d.find(\"filename\").text = \"86.jpg\"\n",
    "d.find(\"filename\").text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "d.write(annot_dir/f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imageai Object detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/Users/hardikmalhotra/Desktop/ML/nanonets-interview/DLAssignment')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Path.joinpath(Path(os.getcwd()), \"DLAssignment\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tracking <tf.Variable 'Variable_10:0' shape=(9, 4) dtype=float32> anchors\n",
      "tracking <tf.Variable 'Variable_11:0' shape=(9, 4) dtype=float32> anchors\n",
      "tracking <tf.Variable 'Variable_12:0' shape=(9, 4) dtype=float32> anchors\n",
      "tracking <tf.Variable 'Variable_13:0' shape=(9, 4) dtype=float32> anchors\n",
      "tracking <tf.Variable 'Variable_14:0' shape=(9, 4) dtype=float32> anchors\n",
      "clock  :  60.18357276916504\n"
     ]
    }
   ],
   "source": [
    "from imageai.Detection import ObjectDetection\n",
    "import os\n",
    "\n",
    "execution_path = Path.joinpath(Path(os.getcwd()), \"DLAssignment\")\n",
    "\n",
    "detector = ObjectDetection()\n",
    "detector.setModelTypeAsRetinaNet()\n",
    "detector.setModelPath(Path.joinpath(Path(os.getcwd()), \"resnet50_coco_best_v2.0.1.h5\"))\n",
    "detector.loadModel()\n",
    "detections = detector.detectObjectsFromImage(input_image=os.path.join(execution_path , \"1.jpg\"), output_image_path=os.path.join(execution_path , \"imagenew.jpg\"))\n",
    "\n",
    "for eachObject in detections:\n",
    "    print(eachObject[\"name\"] , \" : \" , eachObject[\"percentage_probability\"] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom object detection training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "bx_name = [\"bbx_\"+str(i)+\"_name\" for i in range(0,60)]\n",
    "obj_list = df_anno[bx_name].iloc[1].values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1_a',\n",
       " '2_a',\n",
       " '3_b',\n",
       " '4_b',\n",
       " '5_c',\n",
       " '6_ag',\n",
       " '7_c',\n",
       " '8_d',\n",
       " '9_d',\n",
       " '10_p',\n",
       " '11_q',\n",
       " '12_r',\n",
       " '13_s',\n",
       " '14_t',\n",
       " '15_e',\n",
       " '16_k',\n",
       " '17_u',\n",
       " '18_v',\n",
       " '19_w',\n",
       " '20_f',\n",
       " '21_g',\n",
       " '22_g',\n",
       " '23_h',\n",
       " '24_h',\n",
       " '25_f',\n",
       " '26_f',\n",
       " '27_x',\n",
       " '28_i',\n",
       " '29_i',\n",
       " '30_i',\n",
       " '31_j',\n",
       " '32_j',\n",
       " '33_e',\n",
       " '34_k',\n",
       " '35_k',\n",
       " '36_i',\n",
       " '37_i',\n",
       " '38_l',\n",
       " '39_l',\n",
       " '40_l',\n",
       " '41_y',\n",
       " '42_z',\n",
       " '43_m',\n",
       " '44_m',\n",
       " '45_i',\n",
       " '47_n',\n",
       " '48_n',\n",
       " '49_aa',\n",
       " '46_n',\n",
       " '50_n',\n",
       " '51_n',\n",
       " '52_ab',\n",
       " '53_ac',\n",
       " '54_ad',\n",
       " '55_l',\n",
       " '56_ae',\n",
       " '57_af',\n",
       " '58_i',\n",
       " '59_o',\n",
       " '60_o']"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obj_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/hardikmalhotra/Desktop/ML/nanonets-interview'"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating anchor boxes for training images and annotation...\n",
      "not well-formed (invalid token): line 1, column 0\n",
      "Ignore this bad annotation: imageai_data/train/annotations/.DS_Store\n",
      "[Errno 21] Is a directory: 'imageai_data/train/annotations/.ipynb_checkpoints'\n",
      "Ignore this bad annotation: imageai_data/train/annotations/.ipynb_checkpoints\n",
      "Average IOU for 9 anchors: 0.77\n",
      "Anchor Boxes generated.\n",
      "Detection configuration saved in  imageai_data/json/detection_config.json\n"
     ]
    }
   ],
   "source": [
    "from imageai.Detection.Custom import DetectionModelTrainer\n",
    "\n",
    "trainer = DetectionModelTrainer()\n",
    "trainer.setModelTypeAsYOLOv3()\n",
    "trainer.setDataDirectory(data_directory=\"imageai_data/\")\n",
    "trainer.setTrainConfig(object_names_array=obj_list, batch_size=1, num_experiments=50, train_from_pretrained_model=\"pretrained-yolov3.h5\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Errno 21] Is a directory: 'imageai_data/validation/annotations/.ipynb_checkpoints'\n",
      "Ignore this bad annotation: imageai_data/validation/annotations/.ipynb_checkpoints\n",
      "Training on: \t['10_p', '11_q', '12_r', '13_s', '14_t', '15_e', '16_k', '17_u', '18_v', '19_w', '1_a', '20_f', '21_g', '22_g', '23_h', '24_h', '25_f', '26_f', '27_x', '28_i', '29_i', '2_a', '30_i', '31_j', '32_j', '33_e', '34_k', '35_k', '36_i', '37_i', '38_l', '39_l', '3_b', '40_l', '41_y', '42_z', '43_m', '44_m', '45_i', '46_n', '47_n', '48_n', '49_aa', '4_b', '50_n', '51_n', '52_ab', '53_ac', '54_ad', '55_l', '56_ae', '57_af', '58_i', '59_o', '5_c', '60_o', '6_ag', '7_c', '8_d', '9_d']\n",
      "Training with Batch Size:  1\n",
      "Number of Experiments:  50\n",
      "Training with transfer learning from pretrained Model\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "Reshape cannot infer the missing input size for an empty tensor unless all specified input sizes are non-zero\n\t [[{{node replica_0_9/model_33/yolo_layer_31/Reshape}}]]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-108-a51080441509>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda2/envs/nanonets/lib/python3.6/site-packages/imageai/Detection/Custom/__init__.py\u001b[0m in \u001b[0;36mtrainModel\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    289\u001b[0m             \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    290\u001b[0m             \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 291\u001b[0;31m             \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    292\u001b[0m         )\n\u001b[1;32m    293\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/nanonets/lib/python3.6/site-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[1;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/nanonets/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1730\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1731\u001b[0m             \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1732\u001b[0;31m             initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1733\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/nanonets/lib/python3.6/site-packages/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m    218\u001b[0m                                             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m                                             \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 220\u001b[0;31m                                             reset_metrics=False)\n\u001b[0m\u001b[1;32m    221\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/nanonets/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight, reset_metrics)\u001b[0m\n\u001b[1;32m   1512\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1513\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1514\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1515\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1516\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mreset_metrics\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/nanonets/lib/python3.6/site-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3074\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3075\u001b[0m     fetched = self._callable_fn(*array_vals,\n\u001b[0;32m-> 3076\u001b[0;31m                                 run_metadata=self.run_metadata)\n\u001b[0m\u001b[1;32m   3077\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_fetch_callbacks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3078\u001b[0m     return nest.pack_sequence_as(self._outputs_structure,\n",
      "\u001b[0;32m~/anaconda2/envs/nanonets/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1439\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1440\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/nanonets/lib/python3.6/site-packages/tensorflow/python/framework/errors_impl.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type_arg, value_arg, traceback_arg)\u001b[0m\n\u001b[1;32m    526\u001b[0m             \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    527\u001b[0m             \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 528\u001b[0;31m             c_api.TF_GetCode(self.status.status))\n\u001b[0m\u001b[1;32m    529\u001b[0m     \u001b[0;31m# Delete the underlying status object from memory otherwise it stays alive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    530\u001b[0m     \u001b[0;31m# as there is a reference to status from this from the traceback due to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Reshape cannot infer the missing input size for an empty tensor unless all specified input sizes are non-zero\n\t [[{{node replica_0_9/model_33/yolo_layer_31/Reshape}}]]"
     ]
    }
   ],
   "source": [
    "trainer.trainModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (nanonets)",
   "language": "python",
   "name": "nanonets"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
